{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install Required Packages\n",
        "\n",
        "This cell installs all necessary Python packages for Azure Machine Learning, Hugging Face Transformers, and related dependencies.\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-ml azure-identity transformers accelerate\n",
        "!pip install --upgrade jupyter ipywidgets tqdm huggingface_hub transformers"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749108503725
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Define Deployment Variables\n",
        "\n",
        "This cell defines all key variables used throughout the deployment process.  \n",
        "**Please replace the values of all variables starting with `target_` to match your Azure and model context.**\n",
        "\n",
        "**Variable remarks:**\n",
        "- `target_huggingface_model_id`: The Hugging Face model ID to download (e.g., `\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"`).\n",
        "- `target_subscription_id`: Your Azure subscription ID.\n",
        "- `target_resource_group_name`: The Azure resource group name where your ML workspace resides.\n",
        "- `target_workspace_name`: The Azure ML workspace name.\n",
        "- `target_azml_model_name`: The name to register your model under in Azure ML.\n",
        "- `target_azml_model_desp`: Description for your registered model.\n",
        "- `target_managed_endpoint_name`: Name for the Azure ML managed online endpoint.\n",
        "- `target_deployment_prefix`: Prefix for deployment naming (often includes hardware type).\n",
        "- `target_GPU_SKU`: The Azure VM SKU for GPU resources (e.g., `\"Standard_NC4as_T4_v3\"`).\n",
        "- `target_deepseek_env`: Name for the custom Azure ML environment.\n",
        "\n",
        "---\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "target_huggingface_model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "target_subscription_id = \"\"\n",
        "target_resource_group_name = \"\"\n",
        "target_workspace_name = \"\"\n",
        "target_azml_model_name = \"deepseek-qwen-1o5b\"\n",
        "target_azml_model_desp = \"DeepSeek-R1-Distill-Qwen-1.5B for inference\"\n",
        "target_managed_endpoint_name = \"\"\n",
        "target_deployment_prefix = \"nvidia-t4-4core\"\n",
        "target_GPU_SKU = \"Standard_NC4as_T4_v3\"\n",
        "target_deepseek_env = \"deepseek-env\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749173288511
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Create and Register Azure ML Environment\n",
        "\n",
        "This cell creates a custom Azure ML environment with the required dependencies and registers it to your workspace.\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Create a new Azure ML environment\n",
        "env = Environment(name=target_deepseek_env)\n",
        "\n",
        "# Set the Docker base image\n",
        "env.docker.base_image = \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\"\n",
        "\n",
        "# Define Conda dependencies\n",
        "conda_deps = CondaDependencies()\n",
        "\n",
        "# Add Conda and pip packages\n",
        "conda_deps.add_conda_package(\"python=3.10\")\n",
        "conda_deps.add_conda_package(\"pip\")\n",
        "conda_deps.add_pip_package(\"torch\")\n",
        "conda_deps.add_pip_package(\"transformers\")\n",
        "conda_deps.add_pip_package(\"accelerate\")\n",
        "conda_deps.add_pip_package(\"sentencepiece\")\n",
        "conda_deps.add_pip_package(\"protobuf\")\n",
        "conda_deps.add_pip_package(\"azureml-inference-server-http\")\n",
        "\n",
        "# Assign the dependencies to the environment\n",
        "env.python.conda_dependencies = conda_deps\n",
        "\n",
        "\n",
        "# Get the workspace\n",
        "ws = Workspace.get(\n",
        "    name=target_workspace_name,\n",
        "    resource_group=target_resource_group_name,\n",
        "    subscription_id=target_subscription_id  # You can omit this if using a config file\n",
        ")\n",
        "\n",
        "# print(\"Workspace loaded:\", ws.name)\n",
        "# Register the environment to the workspace (replace `ws` with your workspace object)\n",
        "env.register(workspace=ws)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749173289639
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Authenticate and Initialize MLClient\n",
        "\n",
        "This cell authenticates using Azure credentials and initializes the MLClient for further operations.\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient(\n",
        "    credential,\n",
        "    subscription_id=target_subscription_id,\n",
        "    resource_group_name=target_resource_group_name,\n",
        "    workspace_name=target_workspace_name\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749173303569
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Download and Save Hugging Face Model\n",
        "\n",
        "This cell downloads the specified Hugging Face model and tokenizer, then saves them locally for Azure ML registration.\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = target_huggingface_model_id\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True,ignore_mismatched_sizes=True )\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, ignore_mismatched_sizes=True)\n",
        "\n",
        "\n",
        "model.save_pretrained(f\"./{target_azml_model_name}\")\n",
        "tokenizer.save_pretrained(f\"./{target_azml_model_name}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749173605374
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Register Model in Azure ML\n",
        "\n",
        "This cell registers the locally saved model directory as a custom model in Azure ML.\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "\n",
        "model_path = f\"./{target_azml_model_name}\"\n",
        "\n",
        "registered_model = ml_client.models.create_or_update(\n",
        "    Model(\n",
        "        path=model_path,\n",
        "        name=target_azml_model_name,\n",
        "        type=\"custom_model\",\n",
        "        description=target_azml_model_desp\n",
        "    )\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749175515237
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Create and Deploy Managed Online Endpoint\n",
        "\n",
        "This cell creates a managed online endpoint and deploys the registered model to it using the specified environment and compute resources.\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, CodeConfiguration\n",
        "from datetime import datetime\n",
        "\n",
        "# 1. Create a unique endpoint name\n",
        "endpoint_name = target_managed_endpoint_name\n",
        "\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,\n",
        "    auth_mode=\"AADToken\"\n",
        ")\n",
        "\n",
        "ml_client.begin_create_or_update(endpoint).result()\n",
        "\n",
        "# 2. Create a unique deployment name using a prefix and timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "deployment_name = f\"{target_deployment_prefix}-{timestamp}\"\n",
        "\n",
        "print(\"deployment_name:\", deployment_name)\n",
        "\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=deployment_name,\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=f\"{target_azml_model_name}:1\",  # Replace with your model version if different\n",
        "    instance_type=target_GPU_SKU,  # T4 GPU\n",
        "    instance_count=1,\n",
        "    environment=f\"{target_deepseek_env}:1\",  # Optional: define if needed\n",
        "    code_configuration=CodeConfiguration(code=\"./src\", scoring_script=\"score.py\")\n",
        ")\n",
        "\n",
        "\n",
        "# Deploy to the existing endpoint\n",
        "ml_client.begin_create_or_update(deployment).result()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749178169153
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Set Default Deployment and Traffic\n",
        "\n",
        "This cell sets the default deployment for the endpoint and assigns 100% traffic to it.\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "\n",
        "# Get the existing endpoint\n",
        "endpoint = ml_client.online_endpoints.get(name=endpoint_name)\n",
        "\n",
        "# Set the default deployment\n",
        "endpoint.defaults = {\"deployment_name\": deployment_name}\n",
        "\n",
        "# Assign 100% traffic to the specified deployment\n",
        "endpoint.traffic = {deployment_name: 100}\n",
        "\n",
        "# Update the endpoint\n",
        "ml_client.begin_create_or_update(endpoint).result()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749178211670
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Test the Deployed Endpoint\n",
        "\n",
        "This cell sends a sample inference request to the deployed endpoint and prints the model's response.\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import json\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Initialize ML client\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient(credential, target_subscription_id, target_resource_group_name, target_workspace_name)\n",
        "\n",
        "# Get the endpoint object\n",
        "endpoint = ml_client.online_endpoints.get(name=target_managed_endpoint_name)\n",
        "\n",
        "# Extract the scoring URL\n",
        "url = endpoint.scoring_uri\n",
        "print(\"Scoring URL:\", url)\n",
        "\n",
        "# Prepare request data\n",
        "data = {\n",
        "    \"prompt\": \"where does the sun rise?\",\n",
        "    \"max_new_tokens\": 100,\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_p\": 0.7\n",
        "}\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "# Get token using Microsoft Entra ID\n",
        "token = credential.get_token(\"https://ml.azure.com/.default\").token\n",
        "\n",
        "# Set headers with Entra ID token\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Accept': 'application/json',\n",
        "    'Authorization': f'Bearer {token}'\n",
        "}\n",
        "\n",
        "# Create and send request\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "    result = response.read()\n",
        "    print(\"Model response:\")\n",
        "    print(result.decode(\"utf-8\"))\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code:\", error.code)\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749178305569
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}